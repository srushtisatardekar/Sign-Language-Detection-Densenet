{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141b69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c52dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to the folder containing the images\n",
    "images_folder = \"/Users/srushtisatardekar/Downloads/SIGN LANG SRUSH 2/train\"\n",
    "\n",
    "# set the desired size for the images\n",
    "desired_size = (224, 224)\n",
    "\n",
    "# read the images and labels\n",
    "images = []\n",
    "labels = []\n",
    "for letter in range(ord('A'), ord('Z')+1):\n",
    "    folder = os.path.join(images_folder, chr(letter))\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_COLOR)\n",
    "            img = cv2.resize(img, desired_size)\n",
    "            images.append(img)\n",
    "            labels.append(letter - ord('A'))\n",
    "\n",
    "images = np.stack(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalize the pixel values of the images\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=x_train[0].shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {loss:.3f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# save the model\n",
    "model.save(\"sign_language_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0bead0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6680984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load the trained model\n",
    "model = load_model(\"sign_language_classifier.h5\")\n",
    "\n",
    "# set the desired size for the images\n",
    "desired_size = (224, 224)\n",
    "\n",
    "# create a dictionary to map class indices to labels\n",
    "label_dict = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', \n",
    "              10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S',\n",
    "              19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'}\n",
    "\n",
    "# start capturing video from the default camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # read a frame from the video feed\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # convert the frame to color\n",
    "    color = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # resize the frame to the desired size\n",
    "    resized = cv2.resize(color, desired_size)\n",
    "    \n",
    "    # normalize the pixel values of the image\n",
    "    normalized = resized.astype('float32') / 255\n",
    "    \n",
    "    # reshape the image to match the input shape of the model\n",
    "    reshaped = np.reshape(normalized, (1, desired_size[0], desired_size[1], 3))\n",
    "    \n",
    "    # use the model to make a prediction\n",
    "    prediction = model.predict(reshaped)\n",
    "    \n",
    "    # get the class label for the prediction\n",
    "    predicted_class = label_dict[int(np.argmax(prediction))]\n",
    "    \n",
    "    # display the class label on the frame\n",
    "    cv2.putText(frame, predicted_class, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # display the frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # wait for 'q' key to be pressed to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397fa2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
